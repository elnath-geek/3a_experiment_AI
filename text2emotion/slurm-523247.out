# get_cosine_with_hard_restarts_schedule_with_warmup
# num_cycleを設定しないとcosineと同じなのでやり直し

I1115 16:28:46.772422 47507309898432 file_utils.py:41] PyTorch version 1.5.0+cu92 available.
I1115 16:29:08.530913 47507309898432 tokenization_utils.py:501] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/u00461/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
I1115 16:29:23.443022 47507309898432 configuration_utils.py:256] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/u00461/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
I1115 16:29:23.444318 47507309898432 configuration_utils.py:292] Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 6,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30522
}

I1115 16:29:24.312782 47507309898432 modeling_utils.py:461] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/u00461/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
I1115 16:29:28.838178 47507309898432 modeling_utils.py:546] Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.bias', 'classifier.weight']
I1115 16:29:28.840626 47507309898432 modeling_utils.py:552] Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
I1115 16:36:41.223272 47507309898432 configuration_utils.py:118] Configuration saved in working2/model/config.json
I1115 16:36:41.598162 47507309898432 modeling_utils.py:298] Model weights saved in working2/model/pytorch_model.bin
I1115 16:44:01.331281 47507309898432 configuration_utils.py:118] Configuration saved in working2/model/config.json
I1115 16:44:02.487618 47507309898432 modeling_utils.py:298] Model weights saved in working2/model/pytorch_model.bin
/home/u00461/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/u00461/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
I1115 16:51:21.882827 47507309898432 configuration_utils.py:118] Configuration saved in working2/model/config.json
I1115 16:51:22.293284 47507309898432 modeling_utils.py:298] Model weights saved in working2/model/pytorch_model.bin
HBox(children=(HTML(value='Epoch'), FloatProgress(value=0.0, max=3.0), HTML(value='')))
<======================Epoch {_} ======================>

	Current Learning rate:  1.5000000000000002e-05

	Average Training loss:  0.34924409562328146

	Validation Accuracy:  0.9285714285714286

	Validation MCC Accuracy:  0.9060349639838199
              precision    recall  f1-score   support

       anger   1.000000  1.000000  1.000000         2
        fear   1.000000  1.000000  1.000000         3
         joy   1.000000  1.000000  1.000000         3
        love   1.000000  1.000000  1.000000         2
     sadness   1.000000  1.000000  1.000000         5
    surprise   1.000000  1.000000  1.000000         1

    accuracy                       1.000000        16
   macro avg   1.000000  1.000000  1.000000        16
weighted avg   1.000000  1.000000  1.000000        16

<======================Epoch {_} ======================>

	Current Learning rate:  5.000000000000003e-06

	Average Training loss:  0.10553322304337952

	Validation Accuracy:  0.9320436507936508

	Validation MCC Accuracy:  0.9101702766286259
              precision    recall  f1-score   support

       anger   1.000000  0.800000  0.888889         5
        fear   0.750000  1.000000  0.857143         3
         joy   1.000000  1.000000  1.000000         6
        love   0.000000  0.000000  0.000000         0
     sadness   1.000000  1.000000  1.000000         2
    surprise   0.000000  0.000000  0.000000         0

   micro avg   0.937500  0.937500  0.937500        16
   macro avg   0.625000  0.633333  0.624339        16
weighted avg   0.953125  0.937500  0.938492        16

<======================Epoch {_} ======================>

	Current Learning rate:  0.0

	Average Training loss:  0.0763002839369524

	Validation Accuracy:  0.9315476190476191

	Validation MCC Accuracy:  0.9104670164918728
              precision    recall  f1-score   support

       anger   1.000000  1.000000  1.000000         1
        fear   1.000000  1.000000  1.000000         2
         joy   1.000000  1.000000  1.000000         3
        love   1.000000  1.000000  1.000000         1
     sadness   1.000000  1.000000  1.000000         8
    surprise   1.000000  1.000000  1.000000         1

    accuracy                       1.000000        16
   macro avg   1.000000  1.000000  1.000000        16
weighted avg   1.000000  1.000000  1.000000        16


train finished
